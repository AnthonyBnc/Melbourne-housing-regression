{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b292bdc8",
   "metadata": {},
   "source": [
    "# Melbourne Housing Price Prediction - Task 8.2\n",
    "## 1. Data Acquisition and Database Setup \n",
    "This section collects housing data from releastate.com and stores it in a SQLite database for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de32f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database created successfully at: /Users/baoan/Study/University/Deakin/Sem 3 - 2025/SIT720 - ML/Week tasks/Week8/8.2/Melbourne-housing-regression/data/melbourne_housing.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "DB_PATH = DATA_DIR / \"melbourne_housing.db\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS sales (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        suburb TEXT NOT NULL,\n",
    "        postcode TEXT,\n",
    "        address TEXT,\n",
    "        property_type TEXT,\n",
    "        bedrooms INTEGER,\n",
    "        bathrooms INTEGER,\n",
    "        car_spaces INTEGER,\n",
    "        land_size_m2 REAL,\n",
    "        building_size_m2 REAL,\n",
    "        sold_price INTEGER,\n",
    "        sold_date TEXT,\n",
    "        source_url TEXT,\n",
    "        source TEXT DEFAULT 'realestate.com.au',\n",
    "        scraped_at TEXT DEFAULT (datetime('now'))\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE UNIQUE INDEX IF NOT EXISTS idx_unique_listing\n",
    "    ON sales(suburb, address, sold_date, sold_price);\n",
    "    \"\"\")\n",
    "\n",
    "print(\"✅ Database created successfully at:\", DB_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7e2f6",
   "metadata": {},
   "source": [
    "# Create CSV Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d023be88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template CSV file created at ../data/sales_template.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#CSV template\n",
    "template_cols = [\n",
    "    \"suburb\", \"postcode\", \"address\", \"property_type\",\n",
    "    \"bedrooms\", \"bathrooms\", \"car_spaces\",\n",
    "    \"land_size_m2\", \"building_size_m2\",\n",
    "    \"sold_price\", \"sold_date\",\n",
    "    \"source_url\"\n",
    "]\n",
    "\n",
    "template_path = DATA_DIR / \"sales_template.csv\"\n",
    "pd.DataFrame(columns=template_cols).to_csv(template_path, index=False)\n",
    "\n",
    "print(f\"Template CSV file created at {template_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fd512",
   "metadata": {},
   "source": [
    "# Locate and verify HTML files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "275b8913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML files found:\n",
      "- Camberwell1.html\n",
      "- Camberwell2.html\n",
      "- Melbourne1.html\n",
      "- Melbourne2.html\n",
      "- Toorak1.html\n",
      "- Toorak2.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "HTML_DIR = DATA_DIR / \"html\"\n",
    "files = sorted(HTML_DIR.glob(\"*.html\"))\n",
    "\n",
    "print(\"HTML files found:\")\n",
    "for f in files:\n",
    "    print(\"-\", f.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ae07d9",
   "metadata": {},
   "source": [
    "# Helper functions (infer suburb + extract links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ce2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def infer_suburb(filename: str) -> str:\n",
    "    name = filename.lower()\n",
    "    if \"melbourne\" in name:\n",
    "        return \"Melbourne\"\n",
    "    elif \"toorak\" in name:\n",
    "        return \"Toorak\"\n",
    "    elif \"camberwell\" in name:\n",
    "        return \"Camberwell\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def extract_property_links_from_file(path: Path) -> list[str]:\n",
    "    html = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "    links = set()\n",
    "    for a in soup.select(\"a[href]\"):\n",
    "        href = a.get(\"href\", \"\")\n",
    "        if \"/property-\" in href or \"/sold/\" in href:\n",
    "            if href.startswith(\"/\"):\n",
    "                href = \"https://www.realestate.com.au\" + href\n",
    "            if href.startswith(\"https://www.realestate.com.au/\"):\n",
    "                links.add(href.split(\"?\")[0])\n",
    "\n",
    "    return sorted(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ab814f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camberwell1.html: found=55, new=55\n",
      "Camberwell2.html: found=55, new=0\n",
      "Melbourne1.html: found=55, new=53\n",
      "Melbourne2.html: found=51, new=25\n",
      "Toorak1.html: found=59, new=54\n",
      "Toorak2.html: found=55, new=25\n",
      "\n",
      "Summary:\n",
      "Melbourne: 78\n",
      "Toorak: 79\n",
      "Camberwell: 55\n",
      "TOTAL links: 212\n"
     ]
    }
   ],
   "source": [
    "results = {\"Melbourne\": [], \"Toorak\": [], \"Camberwell\": []}\n",
    "seen = set()\n",
    "\n",
    "for f in files:\n",
    "    suburb = infer_suburb(f.name)\n",
    "    if suburb == \"Unknown\":\n",
    "        print(\"Skipping:\", f.name)\n",
    "        continue\n",
    "\n",
    "    urls = extract_property_links_from_file(f)\n",
    "    new_urls = [u for u in urls if u not in seen]\n",
    "\n",
    "    for u in new_urls:\n",
    "        seen.add(u)\n",
    "        results[suburb].append(u)\n",
    "\n",
    "    print(f\"{f.name}: found={len(urls)}, new={len(new_urls)}\")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "total = 0\n",
    "for s in results:\n",
    "    print(f\"{s}: {len(results[s])}\")\n",
    "    total += len(results[s])\n",
    "\n",
    "print(\"TOTAL links:\", total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
